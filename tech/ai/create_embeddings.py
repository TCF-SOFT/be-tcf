import numpy as np
import pandas as pd
import psycopg2
from loguru import logger
from openai import OpenAI
from pgvector.psycopg2 import register_vector
from psycopg2.extras import execute_values
from sqlalchemy import create_engine
from sqlalchemy.engine.url import make_url
from src.config import settings

client = OpenAI(api_key=settings.OPENAI_API_KEY)

# –†–∞–∑–±–æ—Ä SQLAlchemy-style URL ‚Üí psycopg2-—Å–æ–≤–º–µ—Å—Ç–∏–º–∞—è —Å—Ç—Ä–æ–∫–∞
sqlalchemy_url = make_url(settings.DB.PSQL_URL)
psycopg2_dsn = (
    f"dbname={sqlalchemy_url.database} "
    f"user={sqlalchemy_url.username} "
    f"password={sqlalchemy_url.password} "
    f"host={sqlalchemy_url.host} "
    f"port={sqlalchemy_url.port}"
)

# SQLAlchemy engine –¥–ª—è —á—Ç–µ–Ω–∏—è
engine = create_engine(settings.DB.PSQL_URL.replace("asyncpg", "psycopg2"))


BATCH_SIZE = 100


def build_product_text(row):
    parts = [
        row["name"].strip(),
        f"Brand: {row['brand']}" if pd.notnull(row["brand"]) else "",
        f"Manufacturer Number: {row['manufacturer_number']}"
        if pd.notnull(row["manufacturer_number"])
        else "",
        f"Cross Number: {row['cross_number']}"
        if pd.notnull(row["cross_number"])
        else "",
        f"Category: {row['sub_category_slug']}"
        if pd.notnull(row["sub_category_slug"])
        else "",
    ]
    return " | ".join([p for p in parts if p])


def embed_batch(texts: list[str]):
    try:
        response = client.embeddings.create(input=texts, model="text-embedding-3-small")
        return [r.embedding for r in response.data]
    except Exception as e:
        logger.error(f"OpenAI embedding error: {e}")
        return [None] * len(texts)


def bulk_update_embeddings(data):
    with psycopg2.connect(psycopg2_dsn) as conn:
        register_vector(conn)
        with conn.cursor() as cur:
            logger.info(f"‚¨ÜÔ∏è –û–±–Ω–æ–≤–ª—è–µ–º {len(data)} –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ...")
            execute_values(
                cur,
                """
                UPDATE products AS p
                SET embedding = data.embedding::vector
                FROM (VALUES %s) AS data(id, embedding)
                WHERE p.id = data.id
                """,
                data,
                template="(%s, %s)",
            )
            conn.commit()


def main():
    logger.info("üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–≤–∞—Ä—ã –∏–∑ –±–∞–∑—ã...")
    with engine.connect() as conn:
        df = pd.read_sql(
            """
            SELECT id, name, manufacturer_number, brand, cross_number, sub_category_slug
            FROM products
            WHERE name IS NOT NULL
            ORDER BY id
        """,
            conn,
        )

    logger.info(f"üî¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(df)}")
    df["text"] = df.apply(build_product_text, axis=1)

    all_embeddings = []
    logger.info("üí° –ì–µ–Ω–µ—Ä–∞—Ü–∏—è embedding'–æ–≤ –±–∞—Ç—á–∞–º–∏...")
    for start in range(0, len(df), BATCH_SIZE):
        end = start + BATCH_SIZE
        batch = df.iloc[start:end]
        texts = batch["text"].tolist()
        ids = batch["id"].tolist()

        logger.info(f"üß† –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {start}‚Äì{min(end, len(df))} –∏–∑ {len(df)}...")
        embeddings = embed_batch(texts)

        valid_rows = [
            (id_, np.array(embedding))
            for id_, embedding in zip(ids, embeddings)
            if embedding
        ]
        if valid_rows:
            bulk_update_embeddings(valid_rows)
        else:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å embedding –¥–ª—è {len(texts)} —Å—Ç—Ä–æ–∫.")

        all_embeddings.extend(valid_rows)

    logger.info(f"üì¶ –í—Å–µ–≥–æ embedding'–æ–≤ –ø–æ–ª—É—á–µ–Ω–æ: {len(all_embeddings)}")

    logger.success("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")


if __name__ == "__main__":
    main()
